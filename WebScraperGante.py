import pandas as pd
import requests
from bs4 import BeautifulSoup
import time



# ƒåten√≠ URL ze souboru Excel
def read_urls_from_excel(file_path: str) -> list:
    try:
        read = pd.read_excel(file_path)
        urls_read = read["URL"].dropna().tolist()
        return urls_read
    except Exception as e:
        print(f"‚ö†Ô∏è Chyba p≈ôi naƒç√≠t√°n√≠ URL ze souboru: {e}")
        return []



# Cesta k Excel souboru
excel_file = "OdkazyPython.xlsx"
urls = read_urls_from_excel(excel_file)



# T≈ô√≠dy pro hled√°n√≠ cen
no_VAT_class_names = [
    'css-1x63aam ecrn3fv1', 'PriceWithoutTax', 'com-price-product-eshop__price--detail'
]

VAT_class_names = [
    'css-u07su5 ecrn3fv0', 'PriceWithTax', 'com-price-product-eshop__price-vat--detail com-price-product-eshop__price-vat--highlight'
]


# V√Ωsledky
product_prices = []


# Scrapov√°n√≠
for url in urls:
    print(f"üîç Scraping {url}...")
    try:
        page = requests.get(url)
        soup = BeautifulSoup(page.text, 'html.parser')

        product_info = {"URL": url, "Cena bez DPH": "", "Cena s DPH": ""}

        for class_name in no_VAT_class_names:
            element = soup.find('div', class_=class_name)
            if element:
                product_info["Cena bez DPH"] = element.text.strip()
                break

        for class_name in VAT_class_names:
            element = soup.find('div', class_=class_name)
            if element:
                product_info["Cena s DPH"] = element.text.strip()
                break

        product_prices.append(product_info)
        time.sleep(1)

    except Exception as e:
        print(f"‚ö†Ô∏è Chyba p≈ôi zpracov√°n√≠ {url}: {e}")

# Ulo≈æen√≠ do Excelu
df = pd.DataFrame(product_prices, columns=["URL", "Cena bez DPH", "Cena s DPH"])
df.to_excel("CenyPython.xlsx", index=True)
print("‚úÖ Data saved successfully!")
